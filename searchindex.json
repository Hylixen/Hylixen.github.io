{"categories":[{"title":"algorithm","uri":"https://Hylixen.github.io/categories/algorithm/"},{"title":"cs","uri":"https://Hylixen.github.io/categories/cs/"},{"title":"deeplearning","uri":"https://Hylixen.github.io/categories/deeplearning/"},{"title":"hugo","uri":"https://Hylixen.github.io/categories/hugo/"},{"title":"MarkDown","uri":"https://Hylixen.github.io/categories/markdown/"},{"title":"tools","uri":"https://Hylixen.github.io/categories/tools/"}],"posts":[{"content":"常见排序算法 \r 分析排序算法性能\r 执行效率（时间复杂度）  最好时间复杂度（best） 最坏时间复杂度（worst） 平均时间复杂度 （avg）   内存 （空间复杂度） 稳定性  O($n^2$)排序算法 \r 冒泡排序（bubble sort） \r 每次遍历后将最大值交换到最右侧，遍历规模减1。（不变性）每次都会选取出最大值到右侧有序区左端，有序区保持有序，（单调性）每次遍历后遍历规模减小1，因此算法具有正确性。 效率  worst： $O(n^2)$ best: $O(n)$ avg: $O(\\frac{n(n-1)}{4})=O(n^2)$\n排序的交换次数与逆序度相等，分析平均复杂度时依据逆序度进行分析，$满序度=\\frac{n(n-1)}{2}$,$逆序度=满序度-有序度$，逆序度最小为$0$,最大为$\\frac{n(n-1)}{2}$，取均值为$O(\\frac{n(n-1)}{4})=O(n^2)$。  内存 $O(1)$ in place\n稳定性  比较时相等不交换元素稳定  代码实现 template\u0026lt;class T\u0026gt;\rvoid bubble(vector\u0026lt;T\u0026gt;\u0026amp; a){\rcout\u0026lt;\u0026lt;__func__\u0026lt;\u0026lt;\u0026quot;:\u0026quot;\u0026lt;\u0026lt;endl;\rint size = a.size();\rif(size\u0026lt;=1)\rreturn;\rbool f = false;\rfor(int i=0;i\u0026lt;size;++i){\rfor(int j=0;j\u0026lt;size-i-1;++j){\rif(a[j]\u0026gt;a[j+1]){\rswap(a[j],a[j+1]);\rf = true;\r}; } if(!f){\rbreak;\r};\r}\r}\r 插入排序（insertion sort） \r 将数据分为有序无序左右两个区间，每次从无序右区间取左端点加入有序区间，有序区间规模加1，乱序部分规模减1。（不变性）每次都会选取出无序区间元素插入到左区间，左区间保持有序，（单调性）每次插入后无序区间规模减小1，因此算法具有正确性。插入排序与冒泡排序都是 $O(n^2)$,in place排序算法，但插入排序性能更好，应用更多，冒泡排序交换操作常数是3而插入排序的移动操作常数是1.\r效率  worst： $O(n^2)$ best: $O(n)$ avg: $O(n^2)$\n数组插入平均复杂度为$O(n)$，插入n次，因此平均复杂度为$O(n^2)$。  内存  $O(1)$ in place  稳定性  仅在有序元素\u0026gt;插入元素时移动稳定  代码实现 void insertion(vector\u0026lt;int\u0026gt;\u0026amp; a){\rcout\u0026lt;\u0026lt;__func__\u0026lt;\u0026lt;\u0026quot;:\u0026quot;\u0026lt;\u0026lt;endl;\rint size = a.size();\rif(size\u0026lt;=1)\rreturn;\rfor(int i=1;i\u0026lt;size;++i){\rint val = a[i];\rint j = i - 1;\rfor(;j\u0026gt;=0;--j){\rif(val\u0026gt;=a[j]){\rbreak;\r}\ra[j+1] = a[j];\r}\ra[j+1] = val;\r}\r}\r 选择排序 （selection sort） \r 类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。\r效率  worst： $O(n^2)$ best: $O(n^2)$ avg: $O(n^2)$  内存  $O(1)$ in place  稳定性  在swap时可能交换相等元素顺序，不稳定 5* 5 2 \u0026ndash;\u0026gt; 2 5 5*  代码实现 void selection(vector\u0026lt;int\u0026gt;\u0026amp; a){\rcout\u0026lt;\u0026lt;__func__\u0026lt;\u0026lt;\u0026quot;:\u0026quot;\u0026lt;\u0026lt;endl;\rint size = a.size();\rif(size\u0026lt;=1)\rreturn;\rfor(int i=0;i\u0026lt;size;++i){\rfor(int j=i+1;j\u0026lt;size;++j){\rif(a[i]\u0026gt;a[j])\rswap(a[i],a[j]);\r}\r};\r};\r O($nlog(n)$)排序算法 归并排序 （merge sort） \r 利用递归，每次对左右两个区间进行归并排序，直到区间只有不多于两个元素，将有序的子区间数组再自下而上依次合并。\r效率  worst： $O(nlogn)$ best: $O(nlogn)$ avg: $O(nlogn)$\n复杂度分析:\n$$\\begin{aligned}T(n) \u0026amp;=T(\\frac{n}{2}+O(n)) \\\n\u0026amp;= 2(2T(\\frac{n}{2})+\\frac{1}{2}O(n))+O(n)\\\n\u0026amp;= 2^2T(\\frac{n}{2^2})+2O(n) \\\n\u0026amp;= 2^kT(\\frac{n}{2^k})+kO(n) \\\n\u0026amp;= nT(1)+lognO(n) \\\n\u0026amp;= O(nlogn) \\end{aligned}$$  内存  $O(n)$  稳定性  前半段、后半段有相同值时优先合并前半段时稳定  代码实现 void merge(vector\u0026lt;int\u0026gt; \u0026amp;a,int lo,int hi){\rif(hi\u0026lt;=lo)\rreturn;\rint mid = (hi+lo) \u0026gt;\u0026gt; 1;\rint tmp[hi-lo+1];\rint i = lo;\rint j = mid + 1;\rint k = 0;\rwhile(i\u0026lt;=mid\u0026amp;\u0026amp;j\u0026lt;=hi){\rif(a[i]\u0026lt;=a[j]){\rtmp[k++] = a[i++];\r}\relse{\rtmp[k++] = a[j++];\r};\r};\rif(i\u0026lt;=mid){\rwhile(i\u0026lt;=mid)\rtmp[k++] = a[i++];\r};\rif(j\u0026lt;=hi){\rwhile(j\u0026lt;=hi)\rtmp[k++] = a[j++];\r};\rwhile(k\u0026gt;0){\ra[lo+k-1] = tmp[k-1];\r--k; };\r};\rvoid merge_sort(vector\u0026lt;int\u0026gt; \u0026amp;a,int lo,int hi){\rif(hi-lo\u0026lt;=1){\rif(hi\u0026gt;lo\u0026amp;\u0026amp;a[lo]\u0026gt;a[hi]){\rswap(a[lo],a[hi]);\r};\rreturn;\r};\rint mid = (hi+lo)\u0026gt;\u0026gt;1;\rmerge_sort(a,lo,mid);\rmerge_sort(a,mid+1,hi);\rmerge(a,lo,hi);\r};\r  归并排序复杂度为$O(nlogn)$效率稳定但不是in place限制了使用。  快速排序 （quick sort） \r 应用减治思想选取pivot将小于pivot元素放于于左侧，将大于pivot元素放于右边，直至区间长度为1，自上而下排序。\r效率  worst： $O(n^2)$ best: $O(nlogn)$ avg: $O(nlogn)$\n数组有序时可能会退化成$n^2$,选取pivot时加入随机可使复杂度稳定在$O(nlogn)$。  内存  $O(1)$  稳定性  含有swap操作不稳定  代码实现 int partition(vector\u0026lt;int\u0026gt; \u0026amp;v, int lo, int hi){\rint val = v[hi];\rint q = lo;\rfor(int i=lo;i\u0026lt;hi;i++){\rif(v[i]\u0026lt;val){\rswap(v[q++],v[i]);\r}\r}\rswap(v[q],v[hi]);\rreturn q;\r}\rvoid quick_sort(vector\u0026lt;int\u0026gt; \u0026amp;v, int lo, int hi){\rif (lo\u0026gt;=hi)\rreturn;\rint q = partition(v,lo,hi);\rquick_sort(v,lo,q-1);\rquick_sort(v,q+1,hi);\r};\r O($n$)排序算法 桶排序 （bucket sort） \r 将数据分为m桶后排序\r效率  $O(m\\frac{n}{m}log(\\frac{n}{m}))$  内存  取决于内部算法，快排$O(n)$,归并$O(n+n)$  稳定性  取决于内部算法，快排不稳定，归并稳定  代码实现 void bucket_sort(vector\u0026lt;int\u0026gt; \u0026amp;a,int n){\rint size = a.size();\rif(size\u0026lt;=1)\rreturn;\rint _min=a[0];\rint _max=_min;\rfor(auto x:a){\r_min = min(x,_min);\r_max = max(x,_max);\r};\rint step = (_max-_min)/n;\rvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; b(n);\rfor(auto x:a){\rint i = (x/step)-1;\rif(i\u0026lt;0){\rb[0].push_back(x);\rcontinue;\r}\rif(i\u0026gt;=n){\rb[n-1].push_back(x);\rcontinue;\r}\rb[i].push_back(x);\r};\rfor(auto \u0026amp;v:b){\rquick_sort(v,0,v.size()-1);\r};\rint i = 0;\rfor(int k=0;k\u0026lt;n;k++){\rfor(int x:b[k]){\ra[i++] = x;\r};\r};\r}\r 应用情景  数据分布均匀可分区间，比较适合外部排序，大量数据在磁盘上，内存无法全部读取。  计数排序 （count sort） \r \r \r 通过计数和前缀和映射出元素有序位置。\r效率  $O(n+val)$， val为数据范围  内存  O(val)  稳定性  从后往前取数映射时稳定  代码实现 void count_sort(vector\u0026lt;int\u0026gt;\u0026amp; a){\rint size = a.size();\rif(size\u0026lt;=1)\rreturn;\rint _min=a[0];\rint _max=_min;\rfor(auto x:a){\r_min = min(x,_min);\r_max = max(x,_max);\r};\rvector\u0026lt;int\u0026gt; c(_max-_min+1,0);\rfor(auto x:a){\rc[x-_min]++;\r}\rfor(int i=1;i\u0026lt;c.size();i++){\rc[i] += c[i-1];\r}\rvector\u0026lt;int\u0026gt; r(size,0);\rfor(auto x:a){\rr[c[x-_min]-1] = x;\r--c[x-_min];\r};\rint i = 0;\rfor(auto x:r){\ra[i++] = x;\r};\r}\r 应用情景  数据范围有限且为正整数，为负数、浮点数时要转换为等价正整数后再处理。  基数排序 （radix sort） \r 按位由低到高排序\r效率  $O(kO(n))$  内存  取决于内部算法  稳定性  取决于内部算法  应用情景  数据可划分为高低位且位间有递进关系  ","id":0,"section":"posts","summary":"常见排序算法 分析排序算法性能 执行效率（时","tags":["排序"],"title":"排序算法","uri":"https://Hylixen.github.io/2021/06/sort/","year":"2021"},{"content":"Opencv contains multiple modules for image processing,to use them the relative hpp headers files should be included.\n core section defines the basical buliding blocks of the library. (opencv2/core.hpp) imgcodecs module provides functions for reading and writting. (opencv2/imgcodecs.hpp) highgui module provides functions for displaying image in windows. (opencv2/highgui.hpp)  Read images Using imread() function to load the image into a Mat.To aviod error,the parameter filename should be the absolute path of the image.The parameter flags decides the color type of image read as.\n Mat cv::imread( const String \u0026amp; filename,int flags = IMREAD_COLOR)  Mat img = imread(\u0026quot;/home/hylixen/git/cv/rcnn/f/f.jpg\u0026quot;,IMREAD_GRAYSCALE);\r Image read as grayscale is stored in one channel, and as color stored in three channels (BGR).There are three ways to scan the img pixelwise.\n grayscale mat:\n  color mat:\n   The efficient way   The efficient way uses the C style operator[] access.Firstly,get a pointer to the start of each row.Then pass throgh columns of the row (color images has three times than grayscale images).And if the image is stored in continuous,the acess can be speed up by treating the imgae as one row.\nvoid ScanImage(Mat\u0026amp; I,const uchar* const table){\rCV_Assert(I.depth() == CV_8U);\rconst int channels = I.channels();\rint nRows = I.rows;\rint nClos = I.cols * channels;\rif (I.isContinuous()){\rncols *= nRows;\rnRows =1;\r}\rint i,j;\ruchar *p;\rfor(;i \u0026lt; nRows; ++i){\rp = I.ptr\u0026lt;uchar\u0026gt;(i);\rfor ( j = 0; j \u0026lt; nCols; ++j){\rp[j]= table[p[j]];\r}\r}\r}\r   The iterator way   The iterator way can make sure that it passes through the right amount of unchar filed and skips the gaps ,though is slower than the efficient way.\nvoid ScanImageIterator(Mat \u0026amp;I,const unchar* const table){\rCV_Assert(I.depth() == CV_8U);\rconst int channels = I.channels();\rswitch(channels){\rcase 1:\r{\rMatIterator\u0026lt;uchar\u0026gt; it, end;\rfor(it = I.begin\u0026lt;uchar\u0026gt;(), end = I.end\u0026lt;uchar\u0026gt;(); it != endl ; ++it)\r*it = table[*it];\rbreak;\r}\rcase 3:\r{\rMatIterator\u0026lt;Vec3b\u0026gt; it, end;\rfor(it = I.begin\u0026lt;Vec3b\u0026gt;(), end = I.end\u0026lt;vec3b\u0026gt;(); it != endl ; ++it){\r(*it)[0] = table[(*it)[0]];\r(*it)[1] = table[(*it)[1]];\r(*it)[2] = table[(*it)[2]];\r}\r}\r}\r}\r   The random access   It\u0026rsquo;s not recommended for scanning the image because of much tmie consuming.It provides a method to random access the element of the image.\nvoid ImageRanomAccess(Mat \u0026amp;I,const unchar* const table){\rCV_Assert(I.depth() == CV_8U);\rconst int channels = I.channels();\rswitch(channels){\rcase 1:\r{\rfor(int i = 0;i \u0026lt; I.rows; ++i)\rfor(int j = 0; j \u0026lt; I.cols;++j)\rI.at\u0026lt;uchar\u0026gt;(i,j) = table[I.at\u0026lt;uchar\u0026gt;(i,j)]\rbreak;\r}\rcase 3:\r{\rMat_\u0026lt;Vec3b\u0026gt; _I = I;\rfor(int i = 0;i \u0026lt; I.rows; ++i)\rfor(int j = 0; j \u0026lt; I.cols;++j){\r_I(i,j)[0] = table[_I(i,j)[0]];\r_I(i,j)[1] = table[_I(i,j)[1]];\r_I(i,j)[2] = table[_I(i,j)[2]];\r}\rI = _I;\r}\r}\r}\r The Core Function prives a function cv::LUT() for modifying image values that\u0026rsquo;s quite common in image processing,without the need to write the scanning logic.\nMat lookUpTable(1, 256, CV_8U);\ruchar* p = lookUpTable.ptr();\rfor( int i = 0; i \u0026lt; 256; ++i)\rp[i] = table[i];\rLUT(I, lookUpTable, J);\r The official test data on 2560*1600 image:\n   Method Time     efficient way 79.4717 milliseconds   iterator 83.7201 milliseconds   random access 93.7878 milliseconds   LUT function 32.5759 milliseconds    Display and write images If the image is loaded correctly,use imshow() to display the image and [imwrite()] to save the image.\nvoid cv::imshow (const String \u0026amp;winname,InputArray mat)\rbool cv::imwrite (const String \u0026amp;filename,InputArray img,const std::vector\u0026lt; int \u0026gt; \u0026amp; params = std::vector\u0026lt; int \u0026gt;())  imshow(\u0026quot;Display window\u0026quot;, img);\rimwrite(\u0026quot;starry_night.png\u0026quot;, img);\r Reference   OpenCV getting start with images OpenCV scan images   ","id":1,"section":"posts","summary":"Opencv contains multiple modules for image processing,to use them the relative hpp headers files should be included.\n core section defines the basical buliding blocks of the library.","tags":["opencv"],"title":"OpenCV image IO","uri":"https://Hylixen.github.io/2020/08/opencv_imgio/","year":"2020"},{"content":"关于OpenCV  OpenCV是一个开源（BSD协议）的计算机视觉库，它的设计目标是构建一个高效1、简单易用的计算机视觉框架，并提供了c++、java、python接口。OpenCV为解决计算机视觉问题提供基础工具，有些情况下它直接提供了高效解决计算机视觉中复杂问题的高层函数；当没有高层函数时，它提供的基本函数足够为大多数计算机视觉问题创建解决方案。\n  下载和安装OpenCV   (env: ubuntu 20.1)\n  在github官方仓库中clone仓库：\n    git clone https://github.com/opencv/opencv.git    安装编译依赖：    sudo apt install build-essential cmake git pkg-config libgtk-3-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev libjpeg-dev libpng-dev libtiff-dev gfortran openexr libatlas-base-dev python3-dev python3-numpy libtbb2 libtbb-dev libdc1394-22-dev    使用CMake编译并安装：    mkdir build \u0026amp;\u0026amp; cd build cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local .. make -j$nproc sudo make install    安装完成后OpenCV会被默认安装在 /usr/local/lib (动态库目录)与 /usr/local/include/opencv4/（头文件目录），为了时动态库被正确加载避免runtime error要将动态库路径加入配置中。将path加入bash配置或ld.so.conf中：    sudo vim /etc/ld.so.conf.d/opencv.conf add /usr/local/lib/ (where opencv .so locates，using sudo find / -name \u0026ldquo;libopencv*.so.4.4\u0026rdquo; to get the path) to opencv.conf sudo ldconfig -v   OpenCv的结构和内容 结构(未包含CvAux模块2)\n可移植性\nReferences   learnning opencv OpenCV tutorial linux install     （使用c/c++编写，可使用Intel高性能多媒体函数库IPP加速）\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n CvAux放置即将淘汰的算法与函数，新的实验性的算法与函数\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","id":2,"section":"posts","summary":"关于OpenCV OpenCV是一个开源（","tags":["OpenCV","notes"],"title":" Learnning OpenCV  概述","uri":"https://Hylixen.github.io/2020/08/learnning_opencv_ch1/","year":"2020"},{"content":"Abstract This paper developed an efficient segmentation algorithm (time complexity O(nlogn) ) based on graph representation of image and MST(Kruskal\u0026rsquo;s algorithm) using a predicate for measuring the boundary between regions.The predicate is locally adptive and has non-local vision, so the algorithm is able to preserve detail in low-variability regions while ignoring detail in high-variability regions.\nThe problem Intermediate-level vison problems such as stereo, motion estimation and higher-level problems such as recognition, image indexing require broadly useful and efficient segmentation approach that satisfy the following properties:\n Capture perceptually important groupings or regions, which often reflect global aspects of the image. Be highly efficient, running in time nearly linear in the number of image pixels.  Considerable progress in eigenvector-based methods of image segmentation in recent years are to slow for practical applications.And other efficient approaches as classical clustering methods geanerally failed to capture non-local properties as the image shows (this approach locates at down-left). Related work classical formulations of segmentation and recent graph-based methods Graph-based image segmentation techniques generally represent the problem in terms of a graph $G=(V,E)$ where each node $v_i\\in V$ corresponds to a pixel in the image, and the edges in E connect certain pairs of neighboring pixels. A weight is associated with each edge based on some property of the pixels that it connects, such as their image intensities.The earliest graph-based methods use fixed thresholds and local measures in computing a segmentation.\nThe work of Zahn presents a segmentation method based on breaking the large edges of the minimum spanning tree (MST) of the graph.This is not enough to provide a reasonable adaptive segmentation criterion that it depends on the threshold, simply breaking large weight edges would either result in the high variability region being split into multiple regions, or would merge the ramp and the constant region together.The algorithm proposed by Urquhart attempts to address this shortcoming by normalizing the weight of an edge using the smallest weight incident on the vertices touching that edge.But it\u0026rsquo;s not enough to provide a reasonable adaptive segmentation criterion for high variability region.\nAnother early approach to image segmentation is that of splitting and merging regions according to how well each region fits some uniformity criterion.Usually such criteria are aimed at finding either uniform intensity or uniform gradient regions,when a uniformity predicate $U (A)$ is true for some region A then $U (B)$ is also true for any $B \\subset A$(internal difference not preserved well).High variability region would be split into pieces, or it would be merged with the surrounding area too.And the normalized cut criterion also yields an NP-hard computational problem.\nA number of approaches to segmentation are based on finding compact clusters in some feature space.The method firstly transforms the data by smoothing it in a way that preserves boundaries between regions,then finds clusters by dilating each point with a hypersphere of some fixed radius and finding connected components of the dilated points.It first use a novel transformation of the data that this paper do not perform, and then use a fixed dilation radius rather than the variable one that this paper uses).\ndefine pairwise region comparison predicate D internal difference of a component $C\\subseteq V$ to be the largest weight in the minimum spanning tree of the component $MST (C,E)$:\n$$Int(C) = max_{e\\in MST(C,E)} \\quad w(e)$$ minimum internal difference $MInt$ : $$MInt(C_1,C_2)=min(Int(C_1)+\\tau(C_1),Int(C_2)+\\tau(C_2))$$ difference between two components $C_1,C_2\\subseteq V$ to be the minimum weight edge connecting the two components:\n$$Dif(C1,C2)= min_{v_i\\in C1,v_j\\in C2,(v_i,v_j)\\in E} \\quad w((v_i,v_j))$$\npairwise comparison predicate $D$: $$D(C_1,C_2)= \\begin{cases} true \u0026amp; \\text{if } Dif(C_1,C_2)\u0026gt;MInt(C_1,C_2) \\\\\nfalse \u0026amp; \\text{otherwise} \\end{cases}$$\nalgorithm for efficiently segmenting Definition 1 A segmentation S is too fine if there is some pair of regions $C1 , C2 \\in S$,for which there is no evidence for a boundary between them.\nDefinition 2 A segmentation S is too coarse when there exists a proper refinement of S that is not too fine.\nProperty 1 For any (finite) graph $G = (V, E)$ there exists some segmentation S that is neither too coarse nor too fine.\nProof:If the segmentation\u0026rsquo;s elements are in a single component,it\u0026rsquo;s not too fine for there\u0026rsquo;s only one components.If the segmentation is too coarse,keep repeating a proper refinement until obtain a segmentation not too coarse.\nAlgorithm 1 Segmentation algorithm The input is a graph $G = (V, E)$, with n vertices and m edges. The output is a segmentation of V into components $S = (C_1 , . . . , C_r )$.\nSort E into $\\pi = (o_1 , . . . , o_m)$, by non-decreasing edge weight. Start with a segmentation $S_0$ , where each vertex $v_i$ is in its own component. Repeat step 3 for $q = 1, . . . , m$. Construct $S_q$ given $S_{q-1}$ as follows. Let $v_i$ and $v_j$ denote the vertices connected by the q-th edge in the ordering, i.e., $o_q = (v_i , v_j )$. If $v_i$ and $v_j$ are in disjoint components of $S^{q−1}$ and $w(o_q)$ is small compared to the internal difference of both those components, then merge the two components otherwise do nothing. More formally, let $C_i^{q−1}$ be the component of $S_{q−1}$ containing $v_i$ and $C_j^{q−1}$ the component containing $v_j$ . If $C_i^{q−1} \\neq C_j^{q−1}$ and $w(o_q) \\leq MInt(C_i^{q−1} , C_j^{q−1} )$ then $S_q$ is obtained from $S_{q−1}$ by merging $C_i^{q−1}$ and $C_j^{q−1}$ . Otherwise $S_q=S_{q−1}$. Return $S = S_m$.  Analysis and evaluation derive some global properties Lemma 1 In Step 3 of the algorithm, when considering edge $o_q$ , if two distinct components are considered and not merged then one of these two components will be in the final segmentation. Let $C_i^{q−1}$ and $C_j^{q−1}$ denote the two components connected by edge $o_q = (v_i , v_j )$ when this edge is considered by the algorithm. Then either $C_i = C_i^{q−1}$ or $C_j = C_j^{q−1}$, where $C_i$ is the component containing $v_i$ and $C_j$ is the component containing $v_j$ in the final segmentation $S$.\nTheorem 1 The segmentation $S$ produced by Algorithm 1 is not too fine according to Definition 1, using the region comparison predicate $D$.\nTheorem 2 The segmentation $S$ produced by Algorithm 1 is not too coarse according to Definition 2, using the region comparison predicate $D$.\nTheorem 3 The segmentation produced by Algorithm 1 does not depend on which non-decreasing weight order of the edges is used.\nimplementation issues and running time In step 0,it is necessary to sort the weights into non-decreasing order. For integer weights this can be done in linear time using counting sort, and in general it can be done in $O(m \\log m)$ time using any one of several sorting methods.Steps 1-3 of the algorithm take $O(mα(m))$ time, where $α$ is the very slow-growing inverse Ackerman’s function.\nresults for images using the image grid In general the paper use a Gaussian filter to smooth the image slightly before computing the edge weights, in order to compensate for digitization artifacts.use an edge weight function based on the absolute intensity difference between the pixels connected by an edge,\n$$ w((v_i , v_j )) = |I(p_i) − I(p_j)| $$\nwhere I(p i ) is the intensity of the pixel p i. For color images,run algorithm three times, once for each of the red, green and blue color planes, and then intersect these three sets of components(put two neighboring pixels in the same component when they appear in the same component in all three of the color plane segmentations).experimentally better results were obtained by intersecting the segmentations for each color plane than using weight measure distance between pixels in some color space. It\u0026rsquo;s able to preserve detail in low-variability regions while ignoring detail in high-variability regions.\nmethod using more general graphs using general graph in feature space contrast to image grid captures more spatially non-local properies of images for points in nearest neighbors can be far apart in the image while image grid are still neighbors in the image.And the nearest neighbor graph produces similar results to the grid graph for images in which the perceptually salient regions are spatially connected.\nFor interesting regions are not spatially connected,this details won\u0026rsquo;t be obtained by grid graph:\ncode implementation and concept got According to the paper, the algorithm was implemented in MST with simple intensity diffrenence.Maybe the segmentaion should be analysed in different resolution,high resolution for details and low resolution for outlines.\nAnd for obtainning the non-loacl sigmentation not spatially connected,feature space graph is better than image grid graph.\nReference   Pedro F. Felzenszwalb Daniel P. Huttenlocher. Efficient Graph-Based Image Segmentation MST   ","id":3,"section":"posts","summary":"Abstract This paper developed an efficient segmentation algorithm (time complexity O(nlogn) ) based on graph representation of image and MST(Kruskal\u0026rsquo;s algorithm) using a predicate for measuring the boundary between regions.","tags":["cv","segmentation","paper"],"title":"Efficient Graph-Based Image Segmentation","uri":"https://Hylixen.github.io/2020/08/efficien_graph-based_image_segmentation/","year":"2020"},{"content":"big endian and little endian When storing multi-byte objects, the bytes order varies from the architecture of hardware as big endian and little endian.Endians refers to the order in which bytes are stored.It comes from Gulliver\u0026rsquo;s Travels about fought between those who thought eggs should be cracked on the Big End and those who insisted on the Little End.It doesn\u0026rsquo;t really matter as long as you know which end is up.\nLittle Endian:Some hardwares like intel/amd x86, Digital VAX at el, are bulit that store the lowest, least significant byte(LSB) of multi-byte scalars first at lowest memory address.\nBig Endian:Some hardwares like IBM,Powerpc, most RISC machines at el, are bulit that store the highest, most significant byte(MSB) of multi-byte scalars first at lowest memory address.\nendianness and Character Data Single-byte character data such as ASCLL and Latin-1 isn\u0026rsquo;t affected by endianness.\nBut for multi-byte characters in unicode or utf-8 aren\u0026rsquo;t endian-independent.To correctly read them, you need to know the Endianness to store them.\nconversions between endianness To pass muti-byte scalar between machines requires individually \u0026ldquo;byte-swapped\u0026rdquo; to fit other machine\u0026rsquo;s endianness.That requires knowledge of where the scalars are input and the size of them.For UTF-8 ,you can\u0026rsquo;t just simply swap all sequences of four bytes, since not all bytes may belong to four-byte integers.\nSome programs try to finess the problem by converting all scalar data into ASCLL character strings which and the remote machine would convert from ACLL back to native integer format.\nreference  Byte Order - Big and Little Endian  ","id":4,"section":"posts","summary":"big endian and little endian When storing multi-byte objects, the bytes order varies from the architecture of hardware as big endian and little endian.","tags":["bytes order"],"title":"Endianness","uri":"https://Hylixen.github.io/2020/08/endianness/","year":"2020"},{"content":"Definition Spanning tree is a subgraph(every edge belongs to G) of an undirected and connected graph G = (V,E) that spans G (it includes every vertex of G). And a Minimum Spanning Tree is the spanning tree whose costs is minimum. MST is used algorithms approximating the travelling salesman problem, multi-terminal minimum cut problem, minimum-cost weighted perfect matching, cluster analysis, handwriting recognition, image segemention and so on.\nimplementations Prim\u0026rsquo;s algorithm steps:\n Initialize a tree with a single vertex, chosen arbitrarily from the graph Grow the tree by the minimum weight edge that connect the tree to vertics not yet in it. Repeat step 2 until all vertices in the tree.   code:\n#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;vector\u0026gt;\r#include \u0026lt;queue\u0026gt;\r#include \u0026lt;utility\u0026gt;\r#include \u0026lt;functional\u0026gt;\rusing namespace std;\rtypedef pair\u0026lt;long long, int\u0026gt; PII;\rconst int MAX = 1e4 + 5;\rbool marked[MAX];\rvector\u0026lt;PII\u0026gt; adj[MAX];\rlong long prim(int x){\rpriority_queue\u0026lt;PII,vector\u0026lt;PII\u0026gt;,greater\u0026lt;PII\u0026gt;\u0026gt; Q;\rPII p;\rint y;\rlong long cost = 0;\rQ.push(make_pair(0,x));\rwhile(!Q.empty()){\rp = Q.top();\rQ.pop();\rx = p.second;\rif(marked[x] == true)\rcontinue;\rcost += p.first;\rmarked[x] = true;\r//push every vertex conneted to x and not in the tree\rfor(int i = 0;i\u0026lt;adj[x].size();++i){\ry = adj[x][i].second;\rif(marked[y] == false)\rQ.push(adj[x][i]);\r}\r}\rreturn cost;\r}\rint main(){\rint nodes = 0, edges = 0,x = 0, y =0;\rlong long cost = 0, weight = 0;\rcin \u0026gt;\u0026gt; nodes \u0026gt;\u0026gt; edges;\rfor(int i = 0;i \u0026lt; edges;++i){\rcin \u0026gt;\u0026gt; x \u0026gt;\u0026gt; y \u0026gt;\u0026gt; weight;\radj[x].push_back(make_pair(weight, y));\radj[y].push_back(make_pair(weight, x));\r}\rcost = prim(1);\rcout \u0026lt;\u0026lt; \u0026quot;minimum cost:\u0026quot; \u0026lt;\u0026lt; cost \u0026lt;\u0026lt; endl;\rreturn 0;\r}\r complexity:\nKruskal\u0026rsquo;s algorithm steps:\n initialize a disjoint set data structure with elements pointing to themselves sort the edges by weight with ascending order pick edges from the minimum weight and check there\u0026rsquo;s no loop in the forest.   code:\n#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;vector\u0026gt;\r#include \u0026lt;utility\u0026gt;\r#include \u0026lt;algorithm\u0026gt;\rusing namespace std;\rconst int MAX = 1e4 + 5;\rint id[MAX], edges, nodes;\rpair\u0026lt;long long, pair\u0026lt;int,int\u0026gt; \u0026gt;p[MAX];\r//init the forest\rvoid initialize(int nodes){\rfor (int i = 0;i \u0026lt; nodes+1; ++i)\rid[i]=i;\r}\r//find root and havle the path\rint root(int x){\rwhile(id[x]!=x){\rid[x]=id[id[x]];\rx=id[x];\r}\rreturn x;\r}\r//merge two trees\rvoid union_op(int x,int y){\rid[x] = id[y];\r}\rlong long kruskal(pair\u0026lt;long long, pair\u0026lt;int, int\u0026gt;\u0026gt; p[]){\rint x = 0, y = 0;\rlong long total = 0;\rfor (int i = 0;i \u0026lt; edges;++i){\rx=root(p[i].second.first);\ry=root(p[i].second.second);\rif(x != y){\runion_op(x,y);\rcout \u0026lt;\u0026lt; \u0026quot;union: \u0026quot; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026quot;,\u0026quot; \u0026lt;\u0026lt; y \u0026lt;\u0026lt;endl;\rtotal += p[i].first;\r}\r}\rreturn total;\r}\rint main(){\rint nodes = 0,x = 0, y = 0;\rlong long cost = 0, w = 0 ;\rcin \u0026gt;\u0026gt; nodes \u0026gt;\u0026gt; edges;\rinitialize(nodes);\rfor(int i = 0; i \u0026lt; edges; i++){\rcin \u0026gt;\u0026gt; x \u0026gt;\u0026gt; y \u0026gt;\u0026gt; w;\rp[i] = make_pair(w, make_pair(x, y));\r}\rsort(p, p+edges);\rcost = kruskal(p);\rcout \u0026lt;\u0026lt; \u0026quot;cost: \u0026quot; \u0026lt;\u0026lt; cost \u0026lt;\u0026lt; endl;\rreturn 0;\r}\r complexity: O(E log V)\nreferences  Prim\u0026rsquo;s algorithm hackerearth tutorial Kruskal\u0026rsquo;s algorithm in wiki disjoint-set data structure  ","id":5,"section":"posts","summary":"Definition Spanning tree is a subgraph(every edge belongs to G) of an undirected and connected graph G = (V,E) that spans G (it includes every vertex of G).","tags":["MST"],"title":"Minimum Spanning Tree","uri":"https://Hylixen.github.io/2020/07/minimum_spanning_tree/","year":"2020"},{"content":"Origin The Image recognition has four categories of tasks:\n classification:Juge the object classes location:find the object location detection:Judge and locate the objects segementation: Instance-level and Scene-level to classify pixel between objects and scene  In detection tasks,the length of output layer is variable for occurrences of the objects is random.A naive approach to solve the problem would be taking different regions of interest from image and then using CNN to classify the presence of objects of that region.The problem of this approach is objects might have different spatial locations and aspect ratios that would cause computationally blow up for selecting great number of regions.Algorithms like R-CNN,YOLO,SSD,RFCN,RetinaNet,Anchorfree were developed to find these occurrences fast.\ngeneral idea R-CNN uses selective search to extract 2000 regions from the image to bypass a huge number of regions.The candidate region proposals are wraped into square and fed to CNN to extract features for classification by SVM.Finally do Bounding-box regression to adjust location. Problems with R-CNN:\n It cannot be implemented real time as it takes around 47 seconds for each test image and processes 2000 regions. The selective search algorithm is a fixed algorithm. Therefore, no learning is happening at that stage. This could lead to the generation of bad candidate region proposals.  code ","id":6,"section":"posts","summary":"Origin The Image recognition has four categories of tasks:\n classification:Juge the object classes location:find the object location detection:Judge and locate the objects segementation: Instance-level and Scene-level to classify pixel between objects and scene  In detection tasks,the length of output layer is variable for occurrences of the objects is random.","tags":["R-CNN"],"title":"R-CNN","uri":"https://Hylixen.github.io/2020/07/r-cnn/","year":"2020"},{"content":"problem When using markdown to write blogs with hugo ,some troubles about images rendering occurred.Using the following markdown syntax to insert local image :\nsyntax:\r![alt text](image_path \u0026quot;optional capital\u0026quot;)\r![t1](hugos.jpeg \u0026quot;optional capital\u0026quot;)\r![t2](../../static/island.jpg)\r The island.jpg locates at /root/static ,t1 failed to be rendered both in the local markdown render and the web site buit by hugo ,t2 failed in the web site but succeed in local render as follow:\nlocal render:\nweb site:\nsolution There\u0026rsquo;re three ways to insert an image in markdown :\n  to insert local images\n![Alt text](loacl_path \u0026quot;optional title\u0026quot;)    to insert images from url\n![Alt text](link \u0026quot;optional title\u0026quot;)    to insert images transformed to base64 str\n![Alt text](data:image/png;base64,iVBORw0.....)    The first way may have problem in portability for local files.The second one relies much on the network. And the third one affects the writing experience for much long base64 str. Using hugo we can pubish the static web site in the first way but if using absolute path of images ,it won\u0026rsquo;t work.When edit *.md the local render search images in the same level dir of md,so using absolute path t2 was shown in local render but failed in the web site.\nTo fix this there\u0026rsquo;re two ways:\n add your *.md with new post \u0026amp; add images in /root/content/post/your_dir/img_name  using ![alt text](/post/your_dir/img_name) to insert images\r using new post will make copies of post folder to public folder public/post/your_dir/img_name and /\u0026gt;post// would search files in /root/content/post/** by Hugo.\nThe official suggest to put images in static folder.Put images in /root/static/your_dir/img_name and using the following cmd to insert images:  using ![alt text](/your_dir/img_name) to insert images\r Hugo would search images in both /root/content/ and /root/static,images add-in post/ or static/ would be copied in public/ , add-in post/your_dir would be copied in public/post/your_dir/ ,add-in /static/your_dir would be copied in /public/your_dir.\nreference  reference web official web  ","id":7,"section":"posts","summary":"problem When using markdown to write blogs with hugo ,some troubles about images rendering occurred.Using the following markdown syntax to insert local image :","tags":["stacks"],"title":"hugo images in markdown","uri":"https://Hylixen.github.io/2020/07/hugo_about_images/","year":"2020"},{"content":"MarkDown 简介 MarkDown是John Gruber开发的一种轻量级标记语言，它可用纯文本格式进行编辑，对图片及数学公式、html都有支持,可渲染为html、xhtml(more in wiki)。\nMarkDown basic syntax Layers # first layer\r## second layer\r  first layer second layer  Fonts _italic_ **bold** ***bold\u0026amp;_italic_*** text (new line with two blankspace)\r*** split line ~~delete line~~ x[^notation]\r  italic bold bold\u0026amp;italic text    delete line x1  List unordered list\r* item1\r* item11\r* item12\r* item2\r* item21\rorderded list\r1. item1\r2. item2\r3. ...\r unordered list\n item1  item11 item12   item2  item21 \u0026hellip;    ordered list\n item1 item2 \u0026hellip;  Blocks \u0026gt; block1\r\u0026gt;\u0026gt; block2\r\u0026gt;\u0026gt;\u0026gt; block3\r  block1\n block2\n block3\n    block in list\n   block1\n     block2\n     list in block\n   item1 item2    block2\n  Code plaint code blocks start with tab\r1:code blocks\r2:code*** code with hilights\r\\`\\`\\`python\rimport os as as\r\\`\\`\\`\r plaint code blocks start with tab\ncode blocks line 1\rcode line 2  code with hilights using ``` to wrap\nimport os def fun():\rreturn None\rm = 1  Link [link name](address)\r\u0026lt;address\u0026gt;\r[link name][refrence name]\r[refrence name]:https://hylixen.github.io\r  Hylixen\u0026rsquo;s La La Land https://hylixen.github.io link name  tag\nImages ![alt text](image_path \u0026quot;optional capital\u0026quot;)\r Tables |left al|middle al|right al|\r|:------|:-------:|-------:|\r|m |m |m |\r|m |m |m |\r    left al middle al right al     m m m   m m m    Tex exp\r$$\r$$ \\sum_{i=0}^{n}i^2 $$\r $$\\sum_{i=0}^{n}i^2$$\nspan jump to tag\r[text](#tag_name)\r go to tag\n  notation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","id":8,"section":"posts","summary":"MarkDown 简介 MarkDown是John Grub","tags":["MarkDown syntax"],"title":"Markdown","uri":"https://Hylixen.github.io/2020/07/markdown/","year":"2020"}],"tags":[{"title":"bytes order","uri":"https://Hylixen.github.io/tags/bytes-order/"},{"title":"cv","uri":"https://Hylixen.github.io/tags/cv/"},{"title":"MarkDown syntax","uri":"https://Hylixen.github.io/tags/markdown-syntax/"},{"title":"MST","uri":"https://Hylixen.github.io/tags/mst/"},{"title":"notes","uri":"https://Hylixen.github.io/tags/notes/"},{"title":"OpenCV","uri":"https://Hylixen.github.io/tags/opencv/"},{"title":"paper","uri":"https://Hylixen.github.io/tags/paper/"},{"title":"R-CNN","uri":"https://Hylixen.github.io/tags/r-cnn/"},{"title":"segmentation","uri":"https://Hylixen.github.io/tags/segmentation/"},{"title":"stacks","uri":"https://Hylixen.github.io/tags/stacks/"},{"title":"排序","uri":"https://Hylixen.github.io/tags/%E6%8E%92%E5%BA%8F/"}]}